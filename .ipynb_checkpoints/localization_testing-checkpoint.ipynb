{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aefce8fc-7fda-4bfd-8454-4ab1daa795f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, GATv2Conv\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "from typing import Tuple, Dict, List\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59f47809-fa5e-40ac-a1ba-caeaee6ab291",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFEncoder(nn.Module):\n",
    "    def __init__(self, in_dim: int = 2, hid: int = 64, heads: int = 2):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv(\n",
    "            {\n",
    "                ('pixel', 'adjacent', 'pixel'):  # ← 3-tuple!\n",
    "                    GATv2Conv(in_dim, hid,\n",
    "                              heads=heads,\n",
    "                              concat=False,\n",
    "                              add_self_loops=False),\n",
    "                ('pixel', 'ray', 'pixel'):       # ← 3-tuple!\n",
    "                    GATv2Conv(in_dim, hid,\n",
    "                              heads=heads,\n",
    "                              concat=False,\n",
    "                              add_self_loops=False),\n",
    "            },\n",
    "            aggr='mean',\n",
    "        )\n",
    "\n",
    "        self.conv2 = HeteroConv(\n",
    "            {\n",
    "                ('pixel', 'adjacent', 'pixel'):\n",
    "                    GATv2Conv(hid, hid,\n",
    "                              heads=heads,\n",
    "                              concat=False,\n",
    "                              add_self_loops=False),\n",
    "                ('pixel', 'ray', 'pixel'):\n",
    "                    GATv2Conv(hid, hid,\n",
    "                              heads=heads,\n",
    "                              concat=False,\n",
    "                              add_self_loops=False),\n",
    "            },\n",
    "            aggr='mean',\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {k: F.relu(v) for k, v in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return x_dict\n",
    "\n",
    "\n",
    "class RFPredictor(nn.Module):\n",
    "    def __init__(self, node_dim=64):\n",
    "        super().__init__()\n",
    "        self.enc = RFEncoder() # ! changed from out_dim=node_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim * 2, node_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(node_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "                data: HeteroData,\n",
    "                tx_idx,\n",
    "                rx_idx):\n",
    "        # --- 1. get pixel embeddings ------------------------------------\n",
    "        z = self.enc(data.x_dict, data.edge_index_dict)[\"pixel\"]\n",
    "\n",
    "        # --- 2. normalise the indices -----------------------------------\n",
    "        tx_idx = torch.as_tensor(tx_idx, dtype=torch.long, device=z.device)\n",
    "        rx_idx = torch.as_tensor(rx_idx, dtype=torch.long, device=z.device)\n",
    "\n",
    "        if tx_idx.dim() == 0:\n",
    "            tx_idx = tx_idx.unsqueeze(0)\n",
    "            rx_idx = rx_idx.unsqueeze(0)\n",
    "\n",
    "        # --- 3. gather & predict ----------------------------------------\n",
    "        pair_emb = torch.cat([z[tx_idx], z[rx_idx]], dim=-1)\n",
    "        pred = self.mlp(pair_emb).squeeze(-1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a9f8dac-18fd-44f0-9ace-0c8d236341f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_walkable_nodes(mask_path: Path, cell_size: int) -> Tuple[np.ndarray, Dict[Tuple[int, int], int]]:\n",
    "    img = Image.open(mask_path).convert(\"L\")  # grayscale\n",
    "    mask = np.array(img) > 0  # bool\n",
    "    pooled = pool_mask(mask, cell_size)\n",
    "    coords = np.argwhere(pooled)  # (row, col)\n",
    "    id_map = {tuple(coord): idx for idx, coord in enumerate(coords)}\n",
    "    return coords, id_map, pooled.shape[::-1]  # coords, map, (Wc, Hc)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Graph edge construction helpers\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def make_adjacent_edges(coords: np.ndarray, id_map: Dict[Tuple[int, int], int]) -> List[Tuple[int, int]]:\n",
    "    dirs = np.array([[1, 0], [-1, 0], [0, 1], [0, -1]], dtype=int)\n",
    "    edges = []\n",
    "    for coord in coords:\n",
    "        for d in dirs:\n",
    "            nb = tuple(coord + d)\n",
    "            if nb in id_map:\n",
    "                edges.append((id_map[tuple(coord)], id_map[nb]))\n",
    "    return edges\n",
    "\n",
    "\n",
    "def bresenham(p0: Tuple[int, int], p1: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "    x0, y0 = p0\n",
    "    x1, y1 = p1\n",
    "    dx = abs(x1 - x0)\n",
    "    dy = -abs(y1 - y0)\n",
    "    sx = 1 if x0 < x1 else -1\n",
    "    sy = 1 if y0 < y1 else -1\n",
    "    err = dx + dy\n",
    "    line = []\n",
    "    while True:\n",
    "        line.append((x0, y0))\n",
    "        if x0 == x1 and y0 == y1:\n",
    "            break\n",
    "        e2 = 2 * err\n",
    "        if e2 >= dy:\n",
    "            err += dy\n",
    "            x0 += sx\n",
    "        if e2 <= dx:\n",
    "            err += dx\n",
    "            y0 += sy\n",
    "    return line\n",
    "\n",
    "\n",
    "def make_ray_edges(df: pd.DataFrame, id_map: Dict[Tuple[int, int], int], S: int) -> List[Tuple[int, int]]:\n",
    "    edges = set()\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Trace rays\"):\n",
    "        tx = downsample_coord(int(row.tx_location_i), int(row.tx_location_j), S)\n",
    "        rx = downsample_coord(int(row.i), int(row.j), S)\n",
    "        if tx not in id_map or rx not in id_map:\n",
    "            continue\n",
    "        for p0, p1 in zip(bresenham(tx, rx)[:-1], bresenham(tx, rx)[1:]):\n",
    "            if p0 in id_map and p1 in id_map:\n",
    "                u, v = id_map[p0], id_map[p1]\n",
    "                edges.add((u, v))\n",
    "                edges.add((v, u))\n",
    "    return list(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd44f431-f51a-4bb2-b3d7-613e8fe8cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_mask(mask: np.ndarray, cell_size: int = 4):\n",
    "    h, w = mask.shape\n",
    "    h_crop = (h // cell_size) * cell_size         # largest multiple ≤ h\n",
    "    w_crop = (w // cell_size) * cell_size\n",
    "    mask = mask[:h_crop, :w_crop]                 # throw away the ragged fringe\n",
    "\n",
    "    # now safe to reshape/pool\n",
    "    pooled = mask.reshape(h_crop // cell_size, cell_size,\n",
    "                          w_crop // cell_size, cell_size\n",
    "                         ).max(axis=(1, 3))       # OR .mean(...)\n",
    "    return pooled\n",
    "\n",
    "\n",
    "def downsample_coord(row: int, col: int, S: int) -> Tuple[int, int]:\n",
    "    \"\"\"Map original‑resolution (row, col) to coarse grid indices.\"\"\"\n",
    "    return row // S, col // S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ff422d-6b64-4011-a2eb-5261a0ac1c79",
   "metadata": {},
   "source": [
    "## Testing Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "645f812c-473e-4627-94a9-187574ea8a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading model .pt weights\n",
    "state_dict = torch.load('best_model.pt', \n",
    "                        map_location=torch.device(\"cpu\"),\n",
    "                        weights_only=True\n",
    "                       )\n",
    "hidden_dim = 64\n",
    "model = RFPredictor(hidden_dim)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "229d77a7-fec5-49b9-a376-a7337ad188da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trace rays: 100%|██████████████████| 1600000/1600000 [01:17<00:00, 20560.99it/s]\n"
     ]
    }
   ],
   "source": [
    "cell_size = 4\n",
    "\n",
    "coords, id_map, (Wc, Hc) = load_walkable_nodes('train_data/walkable_mask.png', cell_size)\n",
    "adj = make_adjacent_edges(coords, id_map)\n",
    "df = pd.read_csv('train_data/training_walks.csv', delimiter=',')\n",
    "\n",
    "CACHE = f\"train_data/ray_edges_cs{cell_size}.pt\"\n",
    "if not os.path.exists(CACHE):\n",
    "    ray = make_ray_edges(df, id_map, cell_size)\n",
    "    tmp = CACHE + \".tmp\"\n",
    "    torch.save({\"cell_size\": cell_size,\n",
    "                \"edge_index\": ray}, tmp)\n",
    "    os.replace(tmp, CACHE)      # atomic move\n",
    "else:\n",
    "    blob = torch.load(CACHE)\n",
    "    assert blob[\"cell_size\"] == cell_size\n",
    "    ray = blob[\"edge_index\"]\n",
    "\n",
    "data = HeteroData()\n",
    "# node features: normalised coarse‑grid coords (x=j, y=i)\n",
    "xy = coords[:, [1, 0]].astype(np.float32)\n",
    "xy[:, 0] /= Wc; xy[:, 1] /= Hc\n",
    "data[\"pixel\"].x = torch.from_numpy(xy)\n",
    "def to_idx(e):\n",
    "    return to_undirected(torch.tensor(e, dtype=torch.long).t())\n",
    "data[\"pixel\", \"adjacent\", \"pixel\"].edge_index = to_idx(adj)\n",
    "data[\"pixel\", \"ray\", \"pixel\"].edge_index = to_idx(ray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157f220-9e1f-4bea-939b-30546e259b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
